artifacts_root: artifacts # so basically when we are working excuting the training pipelines it creates one folder which is called artifacts which this artifacts it insides saves the data ingestion ,data validation , data tarnsformation , model trainer, model evaluation and everything   


data_ingestion: # here iam defining the data_ingestion related configuration
  root_dir: artifacts/data_ingestion  # here iam creating one data_ingestion folder inside the artifacts
  source_URL: https://github.com/mahendra867/random_datasets/raw/main/TV_Sales.zip # this is my data downloaded URL  by this if we past the URL in the google kaggle winequality dataset get downloaded
  local_data_file: artifacts/data_ingestion/data.zip # when the above data which is present in the line get downloaded it do save inside the local_data_file with name of data.zip
  unzip_dir: artifacts/data_ingestion # again iam unzipping the data file and sending it into data_ingestion



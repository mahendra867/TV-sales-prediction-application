{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\datascience End to End Projects\\\\TV sales prediciton\\\\TV-sales-prediction\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\datascience End to End Projects\\\\TV sales prediciton\\\\TV-sales-prediction'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>15.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.283892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>19.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   15.130500\n",
       "std     85.854236   14.846809   21.778621    5.283892\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   11.000000\n",
       "50%    149.750000   22.900000   25.750000   16.000000\n",
       "75%    218.825000   36.525000   45.100000   19.050000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\mahen\\\\Downloads\\\\advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called the entity \n",
    "from dataclasses import dataclass # here i imported the dataclass from the dataclasses\n",
    "from pathlib import Path  # here i imported path from pathlib\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path  # these are variables which are present inside the config.yaml file data_transformation code part and here iam mentioning inside the entity of the class\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TV_sales.constants import *\n",
    "from TV_sales.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is same part of the code in every step \n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    # only this part get changes in every step, only defining the get_data_transformation_config get changes according to which step we are performing like 01_data_ingestion,02_data_validation\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,  # here iam returning these 2 varaibles by using this code \n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from TV_sales import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here i defined the component of DataTransformationConfig below\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def feature_scalling(self):\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        data.drop('Newspaper',axis=1,inplace=True)\n",
    "        standardized_radio=((data['Radio']-data['Radio'].mean())/data['Radio'].std())\n",
    "        standardized_tv =((data['TV']-data['TV'].mean())/data['TV'].std())\n",
    "        data['Radio'] = standardized_radio # replaced those scalled values in the columns of tv and radio\n",
    "        data['TV'] = standardized_tv\n",
    "\n",
    "        print(data.head)\n",
    "        return data # here iam returning my scaled data to save in the object of this Data_transformation class\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "# here i have defined the tarin_test_split below for performing the train_test_split\n",
    "    def train_test_spliting(self,scaled_data):\n",
    "        \n",
    "\n",
    "        # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "        train, test = train_test_split(scaled_data) # this line splits the data into train_test_split\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False) # here it saves the train and test data in csv format inisde the artifacts-> transformation folder\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "        logger.info(\"Splited data into training and test sets\")\n",
    "        logger.info(train.shape) # this logs the information about that how many training and testing samples i have \n",
    "        logger.info(test.shape)\n",
    "\n",
    "        print(train.head())\n",
    "        print(train.shape)\n",
    "        print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-03 15:49:36,564: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-02-03 15:49:36,567: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-03 15:49:36,572: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-02-03 15:49:36,574: INFO: common: created directory at: artifacts]\n",
      "[2024-02-03 15:49:36,576: INFO: common: created directory at: artifacts/data_transformation]\n",
      "<bound method NDFrame.head of            TV     Radio  Sales\n",
      "0    0.967425  0.979066   22.1\n",
      "1   -1.194379  1.080097   10.4\n",
      "2   -1.512360  1.524637   12.0\n",
      "3    0.051919  1.214806   16.5\n",
      "4    0.393196 -0.839507   17.9\n",
      "..        ...       ...    ...\n",
      "195 -1.267759 -1.317724    7.6\n",
      "196 -0.615491 -1.236899   14.0\n",
      "197  0.348934 -0.940539   14.8\n",
      "198  1.590574  1.261955   25.5\n",
      "199  0.990720 -0.987687   18.4\n",
      "\n",
      "[200 rows x 3 columns]>\n",
      "[2024-02-03 15:49:36,634: INFO: 324909017: Splited data into training and test sets]\n",
      "[2024-02-03 15:49:36,635: INFO: 324909017: (150, 3)]\n",
      "[2024-02-03 15:49:36,636: INFO: 324909017: (50, 3)]\n",
      "           TV     Radio  Sales\n",
      "143 -0.494355 -1.183015   10.4\n",
      "184  1.243474 -0.132284   17.6\n",
      "144 -0.592196 -0.570089   12.3\n",
      "159 -0.178704 -0.327612   12.9\n",
      "101  1.739664  0.878034   23.8\n",
      "(150, 3)\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager() # here iam initlizing my ConfigurationManager\n",
    "    data_transformation_config = config.get_data_transformation_config() # and here iam getting my get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config) # here iam passing my data_transformation_config it means iam calling this data_transformation_config\n",
    "    scaled_data=data_transformation.feature_scalling()\n",
    "    data_transformation.train_test_spliting(scaled_data) # here performing the train_test_split()\n",
    "except Exception as e: # this part of code will raise error if anything goes wrong\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
